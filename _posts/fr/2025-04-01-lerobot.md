---
title: Le Robot
description: Assembler LeRobot de Hugging Face et essayer différentes méthodes pour le manipuler
date: 2025-04-01 11:33:00 +0800
categories: [DIY, AI]
tags: [diy]
image:
  path: assets/img/lerobot/lerobot.webp
  alt: Tous les composants dont vous aurez besoin pour commencer
---

<!-- markdownlint-capture -->
<!-- markdownlint-disable -->


## Qu'est-ce que LeRobot, SO100 ?

### LeRobot

LeRobot est une bibliothèque Python open-source conçue par la communauté de Hugging Face. Son objectif principal est de faciliter l'accès à l'entraînement de robots réels et simulés, permettant aux gens de partager plus facilement des modèles et des ensembles de données.

### SO-100

SO-100 est un autre projet open-source développé spécifiquement pour fonctionner avec la bibliothèque LeRobot. Il est bien documenté et facile à configurer, vous permettant de commencer à enregistrer des ensembles de données rapidement.
> La prochaine génération de la série de bras SO est maintenant disponible ; vous pouvez la trouver dans le même dépôt que SO-100.
{: .prompt-info }

# Assemblage

## Docs

Le processus d'assemblage est déjà bien documenté dans le [dépôt officiel](https://github.com/TheRobotStudio/SO-ARM100), ainsi que quelques vidéos disponibles sur YouTube.

## Ajustements personnels

Avant d'imprimer en 3D toutes les pièces, j'ai aussi cherché un support de caméra. Il n'y en avait aucun disponible dans le dépôt SO-100, alors j'ai conçu le mien. Vous pouvez le trouver [ici](https://makerworld.com/en/models/1288659-lerobot-better-cam-mount#profileId-1318402).


## Contrôle

### ROS2

Après avoir assemblé le robot, j'ai commencé à réfléchir à la façon de le contrôler réellement. En cherchant une solution, j'ai trouvé RoboDK. Après avoir passé du temps à apprendre à l'utiliser, j'ai découvert qu'il n'y avait pas de moyen direct d'importer le SO-100 dans RoboDK, car il est conçu pour des robots industriels avec 6 DDL, tandis que le SO-100 n'en a que 5.
La prochaine chose que j'ai trouvée était ROS 2 (ROS 2 Humble) — le système d'exploitation robotique. En bref, c'est un ensemble de bibliothèques logicielles et d'outils pour aider à construire des applications robotiques. Cela semblait exactement ce dont j'avais besoin. En réalité, cependant, j'ai compliqué le processus de faire bouger le robot. Tout ce dont j'avais vraiment besoin était d'effectuer des calculs IK (cinématique inverse) de base pour le suivi de cible, et peut-être une vérification de collision pour garder les choses sûres.
Quoi qu'il en soit, après une semaine à essayer de créer un package ROS et à écrire un pilote pour importer mon robot dans ROS, j'ai réussi. Peu après, j'ai installé RViz et MoveIt pour visualiser et déplacer le SO-100. Malheureusement, je n'ai pas enregistré à quoi ressemblait l'interface à la fin, mais j'ai cette vidéo timelapse du robot bougeant dans des poses valides aléatoires tout en évitant les collisions :

{% include embed/youtube.html id='hw5OR0U7ehU' %}

À la fin, je n'étais pas vraiment satisfait du résultat et je savais que je devais changer d'approche, car ROS 2 était exagéré pour la tâche dont j'avais besoin.


### Klampt (avec Unity)

Janvier 2026.
Six mois plus tard, je suis revenu à la recherche d'une meilleure façon de contrôler le robot et j'ai découvert Klampt. Klampt est un package (incluant une bibliothèque Python) spécifiquement fait pour la planification de locomotion et de manipulation. Il comprend des fonctionnalités telles que la modélisation de robot, la simulation, la planification, l'optimisation et la visualisation.
Utiliser Klampt était beaucoup plus facile, car je pouvais réutiliser mon package ROS 2 existant au lieu de tout reconstruire à partir de zéro. Puisque mon objectif principal était de contrôler le robot en utilisant un contrôleur VR, j'ai créé un simple projet Unity utilisant OpenXR pour capturer la position et la rotation du contrôleur gauche Meta Quest. Ces données étaient ensuite transmises à Klampt pour IK, vérification de collision et gestion de l'auto-collision.
Voici une vidéo montrant le résultat :

{% include embed/youtube.html id='zfw6B7KmOYk' %}

Il y a plusieurs caméras parce que, à l'avenir, elles seront utiles pour entraîner des ensembles de données. La visualisation Unity elle-même est optionnelle.

## Réflexions finales

Je continuerai ce projet plus tard. La prochaine étape sera de transmettre les angles d'articulation de Klampt à LeRobot afin d'enregistrer des ensembles de données et ensuite entraîner un modèle.
![Vue bureau](assets/img/lerobot/lerobot-2.webp){: width="972" height="589" }
